import os
import csv
import json
import sys

# –ù–∞—Å—Ç—Ä–æ–π–∫–∏
DATA_DIR = "data"
OUTPUT_FILE = "malachite_graph.json"

# –¶–≤–µ—Ç–∞ –¥–ª—è –∫–æ–Ω—Å–æ–ª–∏
C_OK = '\033[92m'
C_WARN = '\033[93m'
C_FAIL = '\033[91m'
C_END = '\033[0m'

def parse_list(cell_data):
    """–ü—Ä–µ–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É 'ID1;ID2' –≤ —Å–ø–∏—Å–æ–∫"""
    if not cell_data or cell_data.strip() == "NULL":
        return []
    return [x.strip() for x in cell_data.split(';') if x.strip()]

def build():
    print(f"üèóÔ∏è  –ó–∞–ø—É—Å–∫ –ú–∞—Ç—Ä–∏—á–Ω–æ–≥–æ –°–±–æ—Ä—â–∏–∫–∞...")
    
    nodes = {}
    categories = {}
    
    # 1. –°–∫–∞–Ω–∏—Ä—É–µ–º –ø–∞–ø–∫–∏ (–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ)
    for root, dirs, files in os.walk(DATA_DIR):
        
        # –ê. –ß–∏—Ç–∞–µ–º –ø–∞—Å–ø–æ—Ä—Ç –ø–∞–ø–∫–∏ (_meta.csv)
        if "_meta.csv" in files:
            meta_path = os.path.join(root, "_meta.csv")
            try:
                with open(meta_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    for row in reader:
                        cat_id = row['ID']
                        categories[cat_id] = {
                            "id": cat_id,
                            "name": row['Name'],
                            "type": "CATEGORY", # –ò–ª–∏ GROUP/BASE
                            "parent_id": row['Parent_ID'],
                            "description": row['Description']
                        }
            except Exception as e:
                print(f"{C_FAIL}–û—à–∏–±–∫–∞ –≤ {meta_path}: {e}{C_END}")

        # –ë. –ß–∏—Ç–∞–µ–º –æ–±—ä–µ–∫—Ç—ã (index.csv)
        if "index.csv" in files:
            index_path = os.path.join(root, "index.csv")
            try:
                with open(index_path, 'r', encoding='utf-8') as f:
                    reader = csv.DictReader(f)
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º ID —Ç–µ–∫—É—â–µ–π –ø–∞–ø–∫–∏ (—á—Ç–æ–±—ã –ø—Ä–∏–≤—è–∑–∞—Ç—å –æ–±—ä–µ–∫—Ç—ã –∫ –Ω–µ–π)
                    current_folder_id = "UNKNOWN"
                    if "_meta.csv" in files:
                        # –ü–µ—Ä–µ—á–∏—Ç—ã–≤–∞–µ–º meta –±—ã—Å—Ç—Ä–æ, —á—Ç–æ–±—ã –≤–∑—è—Ç—å ID
                        with open(os.path.join(root, "_meta.csv"), 'r', encoding='utf-8') as mf:
                            current_folder_id = next(csv.DictReader(mf))['ID']

                    for row in reader:
                        node_id = row['ID']
                        
                        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –≤ –æ–¥–∏–Ω —Å–ª–æ–≤–∞—Ä—å
                        requirements = {
                            "science": parse_list(row.get('Req_Science', '')),
                            "design": parse_list(row.get('Req_Design', '')),
                            "resource": parse_list(row.get('Req_Resource', '')),
                            "material": parse_list(row.get('Req_Material', '')),
                            "infrastructure": parse_list(row.get('Req_Infrastructure', '')),
                            "process": parse_list(row.get('Req_Process', '')),
                            "artifact": parse_list(row.get('Req_Artifact', '')),
                            "society": parse_list(row.get('Req_Society', '')) # –°—Ç–∞—Ä–æ–µ –∏–º—è –∫–æ–ª–æ–Ω–∫–∏
                        }
                        
                        # –°–æ–±–∏—Ä–∞–µ–º –ø–ª–æ—Å–∫–∏–π —Å–ø–∏—Å–æ–∫ —Ä–æ–¥–∏—Ç–µ–ª–µ–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–≤—è–∑–µ–π
                        all_parents = []
                        for req_list in requirements.values():
                            all_parents.extend(req_list)

                        nodes[node_id] = {
                            "id": node_id,
                            "name": row['Name'],
                            "description": row.get('Description', ''),
                            "type": "OBJECT",
                            "folder_category_id": current_folder_id, # –°–≤—è–∑—å —Å –ø–∞–ø–∫–æ–π
                            "level": row.get('Level', 'SPECIFIC'),
                            "requirements": requirements,
                            "all_parents_flat": all_parents
                        }
            except Exception as e:
                print(f"{C_FAIL}–û—à–∏–±–∫–∞ –≤ {index_path}: {e}{C_END}")

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–ø–∞–ø–æ–∫): {len(categories)}")
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ –æ–±—ä–µ–∫—Ç–æ–≤: {len(nodes)}")

    # 2. –í–∞–ª–∏–¥–∞—Ü–∏—è (–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–≤—è–∑–µ–π)
    print(f"\nüîç –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ü–µ–ª–æ—Å—Ç–Ω–æ—Å—Ç–∏...")
    missing_links = 0
    
    for node_id, node in nodes.items():
        for parent in node['all_parents_flat']:
            # –†–æ–¥–∏—Ç–µ–ª—å –º–æ–∂–µ—Ç –±—ã—Ç—å –û–±—ä–µ–∫—Ç–æ–º –ò–õ–ò –ö–∞—Ç–µ–≥–æ—Ä–∏–µ–π
            if parent not in nodes and parent not in categories:
                print(f"{C_WARN}[MISSING] {node['name']} ({node_id}) —Ç—Ä–µ–±—É–µ—Ç --> {parent} (–Ω–µ –Ω–∞–π–¥–µ–Ω–æ){C_END}")
                missing_links += 1

    # 3. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
    full_graph = {
        "meta": {"version": "2.0", "status": "Matrix Ontology"},
        "categories": list(categories.values()),
        "nodes": list(nodes.values())
    }
    
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(full_graph, f, indent=2, ensure_ascii=False)

    if missing_links == 0:
        print(f"\n{C_OK}‚úÖ –£–°–ü–ï–•! –ì—Ä–∞—Ñ —Å–æ–±—Ä–∞–Ω –±–µ–∑ –æ—à–∏–±–æ–∫.{C_END}")
    else:
        print(f"\n{C_WARN}‚ö†Ô∏è –ì—Ä–∞—Ñ —Å–æ–±—Ä–∞–Ω, –Ω–æ –Ω–∞–π–¥–µ–Ω–æ {missing_links} –±–∏—Ç—ã—Ö —Å—Å—ã–ª–æ–∫.{C_END}")
    print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç: {OUTPUT_FILE}")

if __name__ == "__main__":
    build()